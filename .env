# Resource
SPARK_DAEMON_MEMORY=2G
SPARK_DRIVER_CORES=1
SPARK_DRIVER_MEMORY=2G
SPARK_EXECUTOR_CORES=2
SPARK_EXECUTOR_MEMORY=2G

# User
AIRFLOW_UID=0
AIRFLOW_GID=0
SPARK_UID=0
SPARK_GID=0

# Home directory setup
AIRFLOW_HOME=/opt/airflow
DBT_HOME=/home/dbt
AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=10

# Credentials need to match with service postgres-airflow
AIRFLOW_POSTGRES_USER=airflow
AIRFLOW_POSTGRES_PASSWORD=airflow
AIRFLOW_POSTGRES_HOST=postgres-airflow
AIRFLOW_POSTGRES_PORT=5432
AIRFLOW_POSTGRES_DB=airflow

# Credentials need to match with service postgres-dbt
DBT_POSTGRES_PASSWORD=pssd
DBT_POSTGRES_USER=dbtuser
DBT_POSTGRES_DB=dbtdb
DBT_DBT_SCHEMA=dbt
DBT_DBT_RAW_DATA_SCHEMA=dbt_raw_data
DBT_POSTGRES_HOST=postgres-dbt
DBT_POSTGRES_PORT=5432

# Credentials need to match with service postgres-hms
HMS_POSTGRES_PASSWORD=pssd
HMS_POSTGRES_USER=hive
HMS_POSTGRES_DB=metastore
HMS_POSTGRES_HOST=postgres-hms
HMS_POSTGRES_PORT=5432

# Credentials for Airflow SSH Connection
DBT_SSH_HOST=dbt-service
DBT_SSH_PORT=22
SSH_KEY_FILE=/root/.ssh/id_rsa

# For HDFS
HDFS_DEFAULTFS_PORT=9000

# For HMS
HIVE_METASTORE_PORT=9083

# For Spark 
SPARK_APP=/app/spark
SHARED_WORKSPACE=/opt/workspace

SparkVersion=3.0.3
HadoopVersion=3.2
SPARK_HOME=/usr/spark
SPARK_MASTER_HOST=spark-master
SPARK_THRIFT_HOST=spark-thrift
SPARK_MASTER_PORT=7077
SPARK_MASTER_WEBUI_PORT=8082
SPARK_UI_PORT=4040
SPARK_WORKER_PORT=8081
SPARK_THRIFT_PORT=10000

# For Hadoop
HADOOP_HOME=/usr/bin/hadoop-3.2.3

# Credentials for Jupyter Notebook
JUPYTER_TOKEN=welcome
NB_USER=spark
JUPYTER_UID=0
JUPYTER_GID=0
